# Logistic Regression
## Resources Used
## Algorithm
### Hyphotesis Function
m = number of samples, n = number of features, x = training samples in a shape of (n,m), θ = weights in a shape of (n,1) </br>
sigmoid(x) = 1 / (1 + e<sup>-x</sup>) </br>
h<sub>θ</sub>(x) = sigmoid(-θ<sup>T</sup>x) => 1 / (1 + e<sup>θ<sup>T</sup>x</sup>) </br>
### Cost Function (Maximum Likelyhood)
### Gradient Descend
### Regularization
