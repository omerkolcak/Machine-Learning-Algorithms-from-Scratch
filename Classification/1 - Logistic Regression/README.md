# Logistic Regression
## Resources Used
## Algorithm
### Hyphotesis Function
m = number of samples, n = number of features, x = training samples in a shape of (n,m), θ = weights in a shape of (n,1) 
sigmoid(x) = 1 / (1 + e<sup>-x</sup>) 
h<sub>θ</sub>(x) = sigmoid(θ<sup>T</sup>x) => 1 / (1 + e<sup>θ<sup>T</sup>x</sup>)
### Cost Function (Maximum Likelyhood)
### Gradient Descend
### Regularization
